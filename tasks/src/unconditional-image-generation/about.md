## About the Task

Unconditional image generation models usually start with a *seed* that generates a *random noise vector*. The model will then use this vector to create an output image similar to the images used for training the model. 

An example of unconditional image generation would be generating the image of a face on a model trained with the [CelebA dataset](https://huggingface.co/datasets/huggan/CelebA-HQ) or [generating a butterfly](https://huggingface.co/spaces/huggan/butterfly-gan) on a model trained with the [Smithsonian Butterflies dataset](https://huggingface.co/datasets/ceyda/smithsonian_butterflies).

[Generative adversarial networks](https://en.wikipedia.org/wiki/Generative_adversarial_network) and [Diffusion](https://huggingface.co/docs/diffusers/index) are common architectures for this task.

## Use Cases

You can contribute this area with common use cases of the task!

## Model Hosting and Inference

This section should have useful information about Model Hosting and Inference

##Â Useful Resources

- [Hugging Face Diffusion Models Course](https://github.com/huggingface/diffusion-models-class)
- [Getting Started with Diffusers](https://huggingface.co/docs/diffusers/index)
- [Unconditional Image Generation Training](https://huggingface.co/docs/diffusers/training/unconditional_training)

### Training your own model in just a few seconds

In this area, you can insert useful information about training the model