## Task Description

this place describes the task. Contribute by adding a nice description!


## Most used dataset for the task

Write about the data used to train a reinforcement learning model. As reinforcement learning model create its own data, explain about that. 


## Most used model for the task

Contribute by giving example of the model that is used for this task.


## Metrics that are used to evaluate the task

Explain different evaluation techniques which are used to find the underlying weakness of reinforcement learning models.


## Libraries used for the task

Write about different libraries which can be used to implement reinforcement learning algorithms. Explain different features of that library that makes it useful. 


## Use cases

In this part, we will see where we can use these algorithms and how it is helping people in numerous ways.


### Applications in autonomous driving

Autonomous or self-driving cars are pretty trending nowadays. It is also a big step towards driverless commute where the machine is itself able to perform the task. A machine learning model can back the vehicle without any driver. 

In self-driving cars, there are various problems, such as speed limits or drivable zones. The collection of this variety of situations is a challenging problem to solve.

Reinforcement learning can be used to train a model for self-driving cars. Reinforcement Learning models are trained in a dynamic environment by learning a policy from its own experiences, following the principles of exploration and exploitation that minimize disruption to traffic. 

The exploration-exploitation trade-off is a fundamental dilemma whenever you learn about the world by trying things out. The dilemma is between choosing what you know and getting something close to what you expect (‘exploitation’) and choosing something you aren’t sure about and possibly learning more (‘exploration’). 

Exploitation consists of taking the decision assumed to be optimal with respect to the data observed so far. This SAFE approach tries to avoid bad decisions as much as possible but also prevents from discovering potential better decisions.

Exploration consists of not taking the decision that seems to be optimal, assuming that the available data is not sufficient to find the truly optimal solution. This more RISKY approach can sometimes lead to poor decisions but also makes it possible to discover better ones, if there exists any.

Deep Reinforcement learning can learn by itself to operate autonomously in extreme conditions. The dynamic double deep Q-learning (DDQN) model enables the proposed system not be confined to only in known environments. The exploration and exploitation strategies of DDQN enables the autonomous agent to learn proper decisions for various dynamic environments and tracks. The proposed model is tested in a gaming environment. It shows the overall effectiveness in traversing of autonomous land vehicles. The goal is to make the system effective to traverse through undiscovered parts by detecting obstacles.

Scenario based methods for testing and validation of automated driving systems (ADS) in virtual test environments are gaining importance and becoming an essential component for verification and validation processes of ADS. The increase in the cost and complexity of real testing lead to an highly increased efforts in real world testing. Using scenario and simulation based approaches this effort can be efficiently reduced with respect to costs and time. Research has shown that it is necessary to drive and test billions of kilometers to ensure safety of ADS which would not be possible considering the time and cost effort for real testing. The biggest challenges are the selection of a suitable simulation framework and the selection of relevant scenarios for the system under test.

Some of the autonomous driving tasks where reinforcement learning could be applied include trajectory optimization, motion planning, dynamic path finding, controller optimization, and scenario-based learning policies for highways. Reinforcement Learning agents are trained in dynamic environments to optimize trajectories. The agents are capable of accomplishing tasks such as motion planning, route changing, decision and position of parking and speed control.


### NLP (Natural Language processing)

NLP is a branch of machine learning or artificial intelligence concerned with allowing computers to understand the text and spoken words the same way as a human does.  


Language understanding uses Reinforcement Learning because of its inherent nature of decision making it learns from the mistakes. The agent tries to understand the state of the sentence and tries to form an action set maximizing the value it would add.

Reinforcement Learning is used in various NLP tasks such as text summarization, question answering, translation, dialogue generation, or machine translation.


Reinforcement Learning agents can be trained to understand a few sentences of the document and use it to answer the corresponding questions. Reinforcement Learning with a combination of RNN is used to generate the answers for those questions as shown in this paper.

### Applications in Healthcare 

Reinforcement learning can be used to guide patients to the right treatment regime or by choosing the optimized plan for the treatment.

Reinforcement Learning in healthcare is categorized as dynamic treatment regimes(DTRs) in chronic disease or critical care, automated medical diagnosis, and other general domains. The medical sector has always used technological advancements, for past few years it has used the reinforcement learning for implementing dynamic treatment regimes(DTRs) for patients who have long term illness i.e. chronic disease.

It has also found its application in automated medical diagnosis, health resource scheduling, drug discovery and development, and health management.Reinforcement Learning has taken over medical report generation, identification of nodules/tumors and blood vessel blockage, analysis of these reports, etc.

##  Small snippet for inference that demonstrates the task