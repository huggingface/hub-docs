# ðŸ¤— Hugging Face Inference Providers for VS Code Copilot

![Demo](assets/demo.gif)

<!-- Place demo.gif at docs/inference-providers/guides/assets/demo.gif -->

Bring thousands of openâ€‘source models to VS Code Copilot Chat with a firstâ€‘class provider powered by [Hugging Face Inference Providers](https://huggingface.co/docs/inference-providers/index) and built on the [Language Model Chat Provider API](https://code.visualstudio.com/api/extension-guides/ai/language-model-chat-provider).

## âœ¨ Why use the Hugging Face provider in Copilot
- 4k+ openâ€‘source LLMs with tool calling capabilities.
- Single API to thousands of openâ€‘source LLMs via providers like Groq, Cerebras, Together AI, SambaNova, and more.
- Built for high availability and low latency through worldâ€‘class providers.
- No extra markup on provider rates.

---

## âš¡ Quick start
1. Open VS Code's chat interface.
2. Click the model picker and click "Manage Models...".
3. Select "Hugging Face" provider.
4. Provide your Hugging Face Token, you can get one in your [settings page](https://huggingface.co/settings/tokens/new?ownUserPermissions=inference.serverless.write&tokenType=fineGrained).
5. Select the models you want to add to the model picker.

ðŸ’¡ The free tier gives you monthly inference credits to start building and experimenting. Upgrade to [Hugging Face PRO](https://huggingface.co/pro) for even more flexibility, $2 in monthly credits plus payâ€‘asâ€‘youâ€‘go access to all providers!

