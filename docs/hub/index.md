# Hugging Face Hub documentation

<div class="w-full flex flex-wrap justify-evenly gap-y-16">

<div class="w-64 flex flex-col space-y-2 border rounded-xl border-orange-700 px-6 py-4 group">
<span class="flex items-center py-0.5 dark:text-gray-400 text-orange-600 text-xl"><svg class="mr-1.5 text-gray-400 text-orange-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path fill="currentColor" d="M2.6 10.59L8.38 4.8l1.69 1.7c-.24.85.15 1.78.93 2.23v5.54c-.6.34-1 .99-1 1.73a2 2 0 0 0 2 2a2 2 0 0 0 2-2c0-.74-.4-1.39-1-1.73V9.41l2.07 2.09c-.07.15-.07.32-.07.5a2 2 0 0 0 2 2a2 2 0 0 0 2-2a2 2 0 0 0-2-2c-.18 0-.35 0-.5.07L13.93 7.5a1.98 1.98 0 0 0-1.15-2.34c-.43-.16-.88-.2-1.28-.09L9.8 3.38l.79-.78c.78-.79 2.04-.79 2.82 0l7.99 7.99c.79.78.79 2.04 0 2.82l-7.99 7.99c-.78.79-2.04.79-2.82 0L2.6 13.41c-.79-.78-.79-2.04 0-2.82Z"></path></svg> Repositories</span>
<a class="!no-underline hover:opacity-70" href="./repositories-main">Introduction</a>
<a class="!no-underline hover:opacity-70" href="./repositories-getting-started">Getting Started</a>
<a class="!no-underline hover:opacity-70" href="./repositories-best-practices">Best Practices</a>
<a class="!no-underline hover:opacity-70" href="./repositories-next-steps">Next Steps</a>
</div>

<div class="w-64 flex flex-col space-y-2 border rounded-xl border-indigo-700 px-6 py-4 group">
<span class="flex items-center py-0.5 dark:text-gray-400 text-indigo-700 text-xl"><svg class="mr-1.5 text-gray-400 text-indigo-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg> Models</span>
<a class="!no-underline hover:opacity-70" href="./models-main">Introduction</a>
<a class="!no-underline hover:opacity-70" href="./models-the-hub">The Model Hub</a>
<a class="!no-underline hover:opacity-70" href="./models-cards">Model Cards</a>
<a class="!no-underline hover:opacity-70" href="./models-tasks">Tasks</a>
<a class="!no-underline hover:opacity-70" href="./models-interacting">Interacting with models on the Hub</a>
<a class="!no-underline hover:opacity-70" href="./models-widgets">Widgets</a>
<a class="!no-underline hover:opacity-70" href="./models-inference">Inference API</a>
</div>

<div class="w-64 flex flex-col space-y-2 border rounded-xl border-blue-700 px-6 py-4 group">
<span class="flex items-center py-0.5 dark:text-gray-400 text-blue-700 text-xl"><svg class="mr-1.5 text-gray-400 text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg> Spaces</span>
<a class="!no-underline hover:opacity-70" href="./spaces-main">Introduction</a>
<a class="!no-underline hover:opacity-70" href="./spaces-overview">Spaces Overview</a>
<a class="!no-underline hover:opacity-70" href="./spaces-sdks">SDKs</a>
<a class="!no-underline hover:opacity-70" href="./spaces-config-reference">Reference</a>
<a class="!no-underline hover:opacity-70" href="./spaces-changelog">Changelog</a>
</div>

</div>

## What's the Hugging Face Hub?

We are helping the community work together towards the goal of advancing Machine Learning üî•.

The Hugging Face Hub is a platform with over 30K models, 3K datasets, and 2K demos in which people can easily collaborate in their ML workflows. The Hub works as a central place where anyone can share, explore, discover, and experiment with open-source Machine Learning.

No single company, including the Tech Titans, will be able to ‚Äúsolve AI‚Äù by themselves ‚Äì the only way we'll achieve this is by sharing knowledge and resources in a community-centric approach. We are building the largest open-source collection of models, datasets, demos and metrics on the Hugging Face Hub to democratize and advance AI for everyone üöÄ.
## What can you find on the Hub?

The Hugging Face Hub hosts Git-based repositories, which are version-controlled spaces that can contain all your files. üíæ

On it, you'll be able to upload and discover...

* Models, *hosting the latest state-of-the-art models for NLP, vision, and audio tasks*
* Datasets, *featuring a wide variety of data for different domains and modalities*
* Spaces, *interactive apps for demonstrating ML models directly in your browser*

Unlike other hosting solutions, the Hub offers **versioning, commit history, diffs, branches, and over a dozen library integrations**! You can learn more about the features that all repositories share in the **Repositories documentation**.

## Models

Models on the Hugging Face Hub allow for simple discovery and usage to maximize model impact. To promote responsible model usage and development, model repos are equipped with [Model Cards](./models-cards) to inform users of each model's limitations and biases. Additional [metadata](/docs/hub/model-repos#model-card-metadata) about info such as their tasks, languages, and metrics can be included, with training metrics charts even added if the repository contains [TensorBoard traces](https://huggingface.co/models?filter=tensorboard). It's also easy to add an **inference widget** to your model, allowing anyone to play with the model directly in the browser! For production settings, an API is provided to **instantly serve your model**.

To upload models to the Hub, or download models and integrate them into your work, explore the **Models documentation**. You can also choose from [**over a dozen frameworks**](/docs/hub/libraries) such as ü§ó Transformers, Asteroid, and ESPnet that support the Hugging Face Hub.

## Datasets

The Hugging Face Hub is home to over 3,000 datasets in more than 100 languages that can be used for a broad range of tasks across NLP, Computer Vision, and Audio. The Hub makes it simple to find, download, and upload datasets. Datasets are accompanied by extensive documentation in the form of **Dataset Cards** and **Dataset Preview** to let you explore the data directly in your browser. While many datasets are public, **organizations** and individuals can create private datasets to comply with licensing or privacy issues. You can learn more about **Datasets here on Hugging Face Hub documentation**.

[ü§ó `datasets`](https://huggingface.co/docs/datasets/index) allows you to programmatically interact with the datasets, so you can easily use datasets from the Hub in your projects.

## Spaces
[Spaces](https://huggingface.co/spaces) is a simple way to host ML demo apps on the Hub. They allow you to create your ML portfolio, showcase your projects at conferences or to stakeholders, and work collaboratively with other people in the ML ecosystem.

We currently support two awesome SDKs (**[Gradio](https://gradio.app/)** and **[Streamlit](https://streamlit.io/)**) that let you build cool apps in Python in a matter of minutes, with more ways to build coming soon.

After you've explored a few Spaces (take a look at our [Space of the Week!](https://huggingface.co/spaces)), dive into the **Spaces documentation** to learn all about how you can create your own Space.


## Organizations

Companies, universities and non-profits are an essential part of the Hugging Face community! The Hugging Face Hub offers **Organizations**, which can be used to group accounts and manage datasets, models, and Spaces. An organization's repositories will be featured on the organization‚Äôs page and every member of the organization will have the ability to contribute to the repository. In addition to conveniently grouping all of an organization's work, the Hub allows admins to set roles to **control access to repositories**, and manage their organization's [subscription](https://huggingface.co/pricing).

[Explore existing organizations](https://huggingface.co/organizations), create a new organization [here](https://huggingface.co/organizations/new), and then visit the **Organizations documentation** to learn more.

## Security

The Hugging Face Hub supports security and access control features to give you the peace of mind that your code, models, and data are safe. Visit the **Security** section in these docs to learn about:
* User Access Tokens
* Access Control for Organizations
* Signing commits with GPG
* Malware scanning