# Libraries

The Datasets Hub has support for several libraries in the Open Source ecosystem.
Thanks to the [huggingface_hub Python library](../huggingface_hub), it's easy to enable sharing your datasets on the Hub.
We're happy to welcome to the Hub a set of Open Source libraries that are pushing Machine Learning forward.

The table below summarizes the supported libraries and their level of integration.

| Library                                                                     | Description                                                                                                         | Download from Hub | Push to Hub |
|-----------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|---|----|
| [Dask](./datasets-dask) | Parallel and distributed computing library that scales the existing Python and PyData ecosystem.                                                           | âœ… | âœ… |
| [Datasets](./datasets-usage) | ğŸ¤— Datasets is a library for accessing and sharing datasets for Audio, Computer Vision, and Natural Language Processing (NLP).              | âœ… | âœ… |
| [DuckDB](./datasets-duckdb) | In-process SQL OLAP database management system.                                                                                                      | âœ… | âœ… |
| [FiftyOne](./datasets-fiftyone) | FiftyOne is a library for curation and visualization of image, video, and 3D data. | âœ… | âœ… |
| [Argilla](./datasets-argilla) | Collaboration tool for AI engineers and domain experts that value high quality data. | âœ… | âœ… |
| [Distilabel](./datasets-distilabel) | The framework for synthetic data generation and AI feedback. | âœ… | âœ… |
| [Pandas](./datasets-pandas) | Python data analysis toolkit.                                                                                                                    | âœ… | âœ… |
| [WebDataset](./datasets-webdataset) | Library to write I/O pipelines for large datasets.                                                                                       | âœ… | âŒ |
